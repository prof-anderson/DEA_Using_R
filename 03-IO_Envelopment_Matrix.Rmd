---
output:
  html_document: default
  pdf_document: default
---
# Matrix Formulations of DEA

In the previous chapter we created the DEA linear program algebraically using the new ompr package.  Before _ompr_  was available, we needed to use another approach for our DEA package, _TFDEA_, which consisted of using matrices. This approach is requires more "bookkeeping". Both approaches work but I think the algebraic approach is likely to be easier to write, debug, and extend in the future.  For solving, we will use the widely adopted _lpsolveapi_ package. 

People interested in working on the TFDEA package should read this chapter carefully.  We will be returning to these topics algebraically as well later.  For people that want to stick to the algebraic implementation and using _ompr_, you can skip this chapter.  

To get it ready for matrix formulating, we need to  put it in the standard form of linear programs which means that only numbers can be on the right hand side of the inequalities.  
The standard form of linear programming can be described as the following.  

$$
\begin{split}
 \begin{aligned}
    \text{minimize  }   & CX \\
    \text{subject to } & AX \geq B\\ 
                       & X \geq 0  
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOE-Matrix-Simple)
$$

Note that in this form, _X_ is a vector of variables but in DEA _x_ represents inputs.  The vector _X_ will have length equal to the number of units examined plus one more for theta and the number of inputs and the number of outputs.  _C_ is a vector of data with the same number of elements as the _X_ vector.  _A_ is a matrix of data and _B_ is a vector describing the contstraint right hand sides.  

Recall that in the previous chapter we had presented the standard LP model of the input-oriented envelopment model.  

$$
\begin{split}
\begin{aligned}
    \text{minimize  }   & \theta \\
    \text{subject to } & \sum_{j=1}^{N^D} x_{i,j}\lambda_j \leq \theta x_{i,k} \forall \; i\\
                       & \sum_{j=1}^{N^D} y_{r,j}\lambda_j \geq  y_{r,k} \forall \; r\\
                       & \lambda_j \geq 0  \; \forall \; j
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOE-NoSlack)
$$

The first step is to simply move the expression with a variable from the right hand side of the input inequality to the right handside.  

$$
\begin{split}
 \begin{aligned}
    \text{minimize  }   & \theta \\
    \text{subject to } & \sum_{j=1}^{N^D} x_{i,j}\lambda_j - \theta x_{i,k} \leq 0 \forall \; i\\
                       & \sum_{j=1}^{N^D} y_{r,j}\lambda_j \geq  y_{r,k} \forall \; r\\
                       & \lambda_j \geq 0  \; \forall \; j
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOE-Rearranged-NoSlack)
$$

Now we will convert the model's input and output constraints from inequalities into equalities by explicitly defining slack variables.  This isn't necessary just yet but will be used later in the chapter.  

$$
\begin{split}
 \begin{aligned}
    \text{minimize  }   & \theta \\
    \text{subject to } & \sum_{j=1}^{N^D} x_{i,j}\lambda_j - \theta x_{i,k} + s^x_i = 0 \forall \; i\\
                       & \sum_{j=1}^{N^D} y_{r,j}\lambda_j - s^y_r =  y_{r,k} \forall \; r\\
                       & \lambda_j , s^x_i, s^y_r \geq 0  \; \forall \; i,r,j
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOE-Slack)
$$

Now, let's populate the information for our example.

$$
\begin{split}
 \begin{aligned}
    \text{minimize  }   & \begin{bmatrix}
         0 & 0 & 0 & 0 & 1 & 0 & 0
     \end{bmatrix} X \\
    \text{subject to } & \begin{bmatrix}
         10 & 20 & 30 & 50 & -20 & 1 & 0 & \\ 
          75 & 100 & 300 & 400  & 0 & 0 & -1 &
     \end{bmatrix}  X \begin{matrix}
=
\end{matrix}   \begin{bmatrix}
0\\ 
100
\end{bmatrix}\\ 
   & X \geq 0  
  \end{aligned}
\end{split}
(\#eq:LPCCRIOE-Matrix-Example)
$$

If you stare at that too long, you may go "bug-eyed."  The matrix representation is not a very friendly format for people.  Personally I really like the algebraic representations.  This matrix format though works really well for the computer.  The lpSolveAPI package in R is capable of taking an LP model in this form and solving it. Now we just need to structure the data in R to put it in the same format.  

##Creating the LP

Now we are ready to start building our linear program in R.

Now we need to make sure that lpsolveAPI is loaded.  If this does not work, you will need to install the package.

```{r}
## DEA function
library(lpSolveAPI)
library(pander)
```

Now it it gets more involved.  We are defining a function for calculating DEA with options for returns to scale, orientation, and two different options for super-efficiency.

For this walk through, we will focus on running the LP for calculating DEA for only one unit.  We typically would do a loop for every unit but the entire for loop would need to be inside a single R chunk of this document. Instead, we will walk through how the data structure works.  If you understand this, extending it to other units with a for loop is straightforward.

First, let's declare each of the needed basic data structures.  First, determine the number of DMUs, number of inputs, and number of outputs.

```{r Defining_Problem_Size} 
  x <- matrix(c(10,20,30,50),ncol=1,dimnames=list(LETTERS[1:4],"x"))

  y <- matrix(c(75,100,300,400),ncol=1,dimnames=list(LETTERS[1:4],"y"))
  
  ND <- nrow(x); NX <- ncol(x); NY <- ncol(y); 
  
  pander(cbind(x,y),caption="Input-Output Data")
```

Now we will declare the data structures for inputs and outputs that will contain the data that we use.  It is a little redundant to create new objects for the x and y data but there are advanced cases when it is helpful.

```{r Creating_Alternative_Data}
xdata<-x[1:ND,] 
dim(xdata)<-c(ND,NX) 
ydata<-y[1:ND,]
dim(ydata)<-c(ND,NY)
```

Now we can define the structure of the results that we will be calculating.

This is overkill since it has space for results of every unit instead of just the one that we are analyzing now.

```{r Declaring_Structures_of_Results}
  results.efficiency <- matrix(rep(-1.0, ND), nrow=ND, ncol=1)
  results.lambda     <- matrix(rep(-1.0, ND^2), nrow=ND,ncol=ND)
  results.vweight    <- matrix(rep(-1.0, ND*NX), nrow=ND,ncol=NX) 
  results.uweight    <- matrix(rep(-1.0, ND*NY), nrow=ND,ncol=NY) 
  results.xslack     <- matrix(rep(-1.0, ND*NX), nrow=ND,ncol=NX) 
  results.yslack     <- matrix(rep(-1.0, ND*NY), nrow=ND,ncol=NY) 
```

Now it is time for more model options.  

This is where we start creating the populating the linear programming model.  This model declaration creates a problem with the needed number of columns (variables) for standard DEA envelopment models.  

```{r Create_lp_opject}
# This creates an empty LP object that we will populate as appropriate.
    lpe <- make.lp(0,(ND+1+NX+NY))   
```

The name `lpe` is meant to indicate a linear programming object for the envelopment model.  There are two basic DEA models: the envelopment model and the multiplier model.  They generate the same results but are structured very differently.  We'll return to the multiplier model at a later time.

We easily display what our empty `lpe` object looks like.  We are initializing it without any constraints but columns for each variable that we expect to use: 

* Columns for each lambda, _i.e._ $\lambda_1, \lambda_2, ..., lambda_N^D$  
* A column for the efficiency, $\theta$
* Columns for each input slack and each output slack

```{r Display_lp_Empty}
   lpe 
```

The empty LP isn't very interesting but building it up step by step shows what we are doing and why.

This is an important step where we say that we are picking a particular unit to examine.  Since our earlier graphical analysis pointed to unit _B_, we will also look at unit 2.  Changing to a different unit is as simple as changing the number 2.  Of course, even easier is to use a 'for' loop to run through doing it for every unit but that simple change is something that we will also leave for later.  The current format lets me continue to explain how DEA works one chunk of R code at a time.

```{r Which_Unit}
    k <- 2   # Declare a particular unit instead of 
             # using a for loop such    for (k in 1:ND)     
```

The next thing that we will do is to create the objective function.  

In this case, the "1" corresponds to the column for the $\theta$ variable of the input-oriented model. The input-oriented model is a min.  The output-oriented model is a max.  Let's make sure to set the model up accordingly.

```{r}
      lpcontrol <- lp.control(lpe, sense="min") # Set to a minimize function

      set.objfn(lpe, c(rep(0, ND),1,rep(0,NX+NY)))  # Minimize the theta variable.
```

The above commands have two important functions.  The first merely sets it to be a _minimize_ objective function.  The second puts the relevant 0's and 1's in the objective function.  

The lp.control function returns a long list of options being used for the linear programming solver.  The defaults are fine for now and it can take a full page to list all the settings so I just store it into an object, lpcontrol so it doesn't display it for now.


```{r Display_lp_with_Obj}
   lpe 
```

Now we will prepare for adding names to elements of our data matrix.  This is a little tricky so don't worry if these commands are initially confusing.  Also, if you are fluent in R, you can probably come up with more elegant ways of doing this.

```{r Add_names_to_LP}

    lambda_names <- paste("L", 1:ND, sep = "")  # We'll use L to represnt Lambda
    
    eff_name <- "theta"   # Pick the appropriate variable name

    xslack_names <- paste ("sx", 1:NX, sep = "")  
         # These are slack variables instead of inequalities
    yslack_names <- paste ("sy", 1:NY, sep = "")

    ColNames <- c(lambda_names, eff_name, xslack_names, yslack_names)

    x_constraint_names <- paste("Con_X_", 1:NX, sep = "")
    y_constraint_names <- paste("Con_Y_", 1:NY, sep = "")
    
    RowNames <- NULL
 
```

The following step is more complicated but the core idea is to populate a data matrix to describe the constraints for a DEA model.  The first _for_ loop create the row(s) corresponding to input constraints.  

```{r Build_lp_x_constraints}
      for (i in 1:NX) {
          add.constraint(lpe, c(xdata[,i],-1*xdata[k,i], 
                                   if(i>1) rep(0,i-1),+1,if(i<NX) rep(0,NX-i),rep(0,NY)),"=", 0)
          }
   RowNames <- c(RowNames, x_constraint_names )
   dimnames(lpe) <- list(RowNames, ColNames)  # Add X Constraint names to LP

   lpe 
```

Now the rows/contstraints are created for the outputs.      

```{r Build_lp_y_constraints}

      for (r in 1:NY) {
           add.constraint (lpe, c(ydata[,r], 0, rep(0,NX), 
                 if(r>1) rep(0,r-1),-1,if(r<NY) rep(0,NY-r)),"=", ydata[k,r]) 
          }

   RowNames <- c(RowNames, y_constraint_names )
   dimnames(lpe) <- list(RowNames, ColNames)  # Add X Constraint names to LP

   lpe 
```

Set the lower limits for all variables to be 0.0

```{r}
      set.bounds (lpe, lower = rep(0.0, ND+1+NX+NY))  
```

All the variables should be non-negative.  (Technically the radial efficiency scores, $\theta$ is usually declared to be un-restricted in sign but this should not hurt the solution.)

```{r Display_lp_Non-Negativity_constraints }
   lpe 
```

## Solving and Processing Results

Finally, solve the LP to calculate the efficiency score.

```{r}
     solve.lpExtPtr (lpe)
```

Simply solving doesn't tell us anything very useful.  It just gives an error code of 0 (or at least we hope to get that-anything else is worth digging into!) An error code of 0 means that it solved the problem.  When it does so, it adds results to the _lpe_ opbject.  Now we need to extract the results from the solution in a form that we can use.

We have four separate steps.  In the input-oriented model, we read out the objective function value and place it in the _k_'th place of _results.efficiency_.  

The following step sets _Phase1_ equal to the same efficiency score.  We will use this value in a second LP that we creatively refer to as Phase2 in order to make sure that we have an optimal target.  

Next we get input dual weights and place them in _results.vweight_.  These are useful because the dual weights are essentially the solution the DEA multiplier model.  We can also thing of them roughly as the "prices" or "values" placed on inputs and outputs that make the unit appear as good as possible.  (It is tricky that all rows are offset from how you might count them because row 1 is considered to be the objective function.)

The fourth item gets the dual weight from the returns to scale constraint.  Notice that this is extracted from row 2 of the dual solution.

The same steps are repeated for the output-oriented model but sign corrections may need to be made by multiplying these items by _-1_, you can check for yourself if this needs to be done.

The last step of extracting output weights is common for both orientations since it does not require a sign correction.  

```{r Collect_Phase1_Results}
        results.efficiency[k] <-  get.objective(lpe)      
        Phase1 <- get.objective(lpe)
        results.lambda[k,] <- get.variables(lpe)[1:(ND)] # Put lambda values in matrix            
        results.vweight[k,] <- -1 * get.dual.solution(lpe)[2:(1+NX)] 
                                    # Get input weights, v
      
      results.uweight[k,] <- get.dual.solution(lpe)[(2+NX):(1+NX+NY)]
                                    # Get output weights, u
        DMUnames <- list(c(LETTERS[1:ND]))

  
```

Let's look at our results!  

```{r Display_Phase1_Results  }
  Xnames<- lapply(list(rep("X",NX)),paste0,1:NX)
  Ynames<- lapply(list(rep("Y",NY)),paste0,1:NY)
  Vnames<- lapply(list(rep("v",NX)),paste0,1:NX)
  Unames<- lapply(list(rep("u",NY)),paste0,1:NY)
  SXnames<- lapply(list(rep("sx",NX)),paste0,1:NX)
  SYnames<- lapply(list(rep("sy",NY)),paste0,1:NY)
  dimnames(results.lambda)<-c(DMUnames,DMUnames)
  dimnames(results.xslack)<-c(DMUnames,SXnames)
  dimnames(results.yslack)<-c(DMUnames,SYnames)
  dimnames(results.vweight)<-c(DMUnames,Vnames)
  dimnames(results.uweight)<-c(DMUnames,Unames)

results.efficiency [k]  # Display efficiency score for unit k
results.lambda  [k,]    # Display lambda variables
results.vweight [k,]    # Display input weights
results.uweight [k,]    # Display output weights

pander(cbind(results.efficiency [k],results.lambda  [k,]),caption="DEA Efficiency Scores and Lambdas")
pander(cbind(results.vweight [k,],results.uweight [k,]),caption="DEA Multiplier Weights" )
```

## Slack Maximization

This is a little more advanced.  In analyses where our only purpose is to find the efficiency score, we could stop here.  In cases where we want to find the _best_ target for an inefficent unit, we need to go one step further and say that we want to also maximize the slack given that same level of efficiency.  The simple one input, one output case with constant returns to scale won't demonstrate a problem so it is only shown here at this time for completeness and the particularly adventurous reader. 

As long as you are still reading, let's explain a little bit of slack maximization.  Phase 1 gives simple radial efficiency scores but does not necessarily give a best target for efficiency.  The purpose here is to ensure that the $\lambda$ values actually point to the best possible target of performance.

Now we need to do a step that is called slack maximization.  We will need to add constraint that the efficiency variable ($\theta$) is held constant at the value found in Phase 1.  

The linear program is modified in the following manner.  We now want to maximize the sum of both input slack(s) and ouptput slack(s).  

$$
\begin{split}
 \begin{aligned}
    \text{maximize  }  & \sum_{i}s^x_i + \sum_{r}s^y_r\\
    \text{subject to } & \sum_{j=1}^{N^D} \lambda_j  = 1\\
                       & \sum_{j=1}^{N^D} x_{i,j}\lambda_j - \theta x_{i,k} + s^x_i = 0 \; \forall \; i\\
                       & \sum_{j=1}^{N^D} y_{r,j}\lambda_j - s^y_r =  y_{r,k} \; \forall \; r\\
                       & \theta = \theta^*\\
                       & \lambda_j , s^x_i, s^y_r \geq 0  \; \forall \; j
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOE-MaxSlacks)
$$

The following are the changes to the LP object.

```{r}
    ## Maximize sum of slacks
    add.constraint (lpe,c(rep(0,ND),1,rep(0,NX+NY)),"=",Phase1)
         # Hold Efficiency constant
    lpcontrol <- lp.control(lpe, sense="max")  # Change from min to max
    set.objfn (lpe,c(rep(0,ND+1),rep(1,NX+NY))) # Maximize sum of slacks
```

We are now ready to solve phase 2.  We can then extract the values of the $\lambda$ variables and the slack variables.

```{r}
    solve.lpExtPtr (lpe)                                        
    results.lambda[k,] <- get.variables(lpe)[1:(ND)]            
    results.xslack[k,] <- get.variables(lpe)[(ND+2):(ND+1+NX)]  
    results.yslack[k,] <- get.variables(lpe)[(ND+2+NX):(ND+1+NX+NY)]    
```

Again, let's look over the results.  

```{r}
  Xnames<- lapply(list(rep("X",NX)),paste0,1:NX)
  Ynames<- lapply(list(rep("Y",NY)),paste0,1:NY)
  Vnames<- lapply(list(rep("v",NX)),paste0,1:NX)
  Unames<- lapply(list(rep("u",NY)),paste0,1:NY)
  SXnames<- lapply(list(rep("sx",NX)),paste0,1:NX)
  SYnames<- lapply(list(rep("sy",NY)),paste0,1:NY)
  dimnames(results.lambda)<-c(DMUnames,DMUnames)
  dimnames(results.xslack)<-c(DMUnames,SXnames)
  dimnames(results.yslack)<-c(DMUnames,SYnames)

#    results.lambda[k,]         
#    results.xslack[k,]
#    results.yslack[k,]
    pander(cbind(results.lambda[k,],results.xslack[k,],results.yslack[k,]))
```

Now, let's put it all together to summarize the results.

What does this mean?  We are saying that unit `r k` has an efficiency of `r results.efficiency[k]`.  This is obtained by using a vector $\lambda$=`r results.lambda[k,]`.  Also, the weights on input(s) that correspond to this score was `r results.vweight[k,]` and for outputs `r results.uweight[k,]`.  

## Exercises

If you have followed along this far - you deserve a medal!  If you work your way through by cutting and pasting code fragments, you should be able to reproduce my exact results.  At this point you are ready for a few challenges:

1. Graphically determine the efficiency score and lambdas for the other units.  _Difficulty: Decaf cup of coffee_
2. Interpret the solution in terms of who is doing well, who is doing poorly, and who should be learning from whom.  _Difficulty: Cup of coffee_
3. Add a fifth unit, E, that produces 400 units output using 30 units of input.  Graphically evaluate all five units for their efficiency scores and lambda values.  
4. Interpret the solution in terms of who is doing well, who is doing poorly, and who should be learning from whom.  _Difficulty: Cup of coffee_
5. Examine another unit using the R code (hint:  change where k is set.)  _Difficulty: Decaf cup of coffee_
6. Interpret the solution in terms of who is doing well, who is doing poorly, and who should be learning from whom.  _Difficulty: Cup of coffee_
7. Wrap a for loop around the model to examine every unit.  _Difficulty: Cup of coffee_
8. Use a bigger data set (more inputs, outputs, and units.)  _Difficulty: Cup of coffee_
9. Validate results against other DEA packages (ex. Benchmarking, nonparaeff) _Difficulty: Pot of coffee_
10. Construct an example where Phase 2 increases positive slacks from Phase 1.  _Difficulty: Pot of coffee_
11. Create "cool" graphs or plots of results.  _Difficulty: It depends..._

To pass the challenges, work on extending my RMarkdown file or using a similar script.  Some people prefer to use compile all of my code into large chunks in RMarkdown. Others might prefer to create a well documented R script instead of using RMarkdown.  Others might even prefer using LaTeX. If you use RMarkdown or LaTeX, please use section headings to indicate each challenge solved.  

You can use other packages for graphics or data manipulation but don't use a DEA package.  (Don't worry, we'll get there later.)


---
output:
  html_document: default
  pdf_document: default
---
# Multiplier Models

Introduction
-----------------------------

Every linear program has a related alter ego referred to as the dual.  By duality, the two models have the same optimal objective function values.  In DEA, the multiplier models are simply the dual of the envelopment models.  In terms of the matrix representations of DEA given in chapter 3, the A matrix is transposed, rows give way to columns and columns become rows.  The right hand side values appear in the objective function while the previous objective function coefficients become right hand side values.  More could be said about this but this will be deferred for people interested in duality or more algorithmic aspects of linear programming.  

Let's turn our attention instead to intuitively developing the DEA multiplier model through a few steps. 

## The Two Output, No Input Model

Assume that you, Alfred, are one of six restaurant managers of various franchisees of the popular TexMex chain, Chiposter.  Each restaurant branch is operating under different conditions and are operated by your colleagues:  Barb, Chris, Don, Ed, and Fran.  Each restaurant manager is achieving outcomes (outputs.) At the end of the year, you want to make a case for having done well.

```{r multiplier_rest_Y_data }

library(pander)           # For making nice tables

 YRest1 <- matrix(c(25, 14, 42, 18, 19, 14, 3500, 2100, 1050, 
                    4200, 2500, 1500), ncol=2,
                  dimnames=list(c("Alfred", "Barb","Chris", "Don", "Ed","Fran"),
                                c("y1", "y2")))

ND <- nrow(YRest1); NY <- ncol(YRest1); # Define data size

pander(YRest1, caption="Restaurant Data")  

```

You can select any way of weighting the two outputs with just two conditions:

* No weight can be negative
* No one can received a weighted score above 100%

Given these two limitations, your goal is to make your "Alfred score" as high as possible.

While it is possible to experiment with different weights, this can also be framed as an optimization model.  The goal or objective is to find the best Alfred score, using weights ($u_1$, and $u_2$) subject to the constraints that no one's scores is above 100%.  

Let's take the restaurant data and formulate the model.

$$
\begin{split}
\begin{aligned}
    \text {max } & 25 u_1 + 3500 u_2 \\
    \text{subject to } & 25 u_1 + 3500 u_2 \leq 1.0\\
                       & 14 u_1 + 2100 u_2 \leq 1.0\\
                       & 42 u_1 + 1050 u_2 \leq 1.0\\
                       & 18 u_1 + 4200 u_2 \leq 1.0\\
                       & 19 u_1 + 2500 u_2 \leq 1.0\\
                       & 14 u_1 + 1500 u_2 \leq 1.0\\
                       & u_1, u_2\geq 0  \
  \end{aligned}
\end{split}
(\#eq:NLP-HardCode)
$$

Next let's implement this in `ompr` which may serve as a convenient refresher as well.  

```{r}
library(dplyr, quietly=TRUE)            # For data structure manipulation
library(ROI, quietly=TRUE)              # R Optimization Interface package
library(ROI.plugin.glpk, quietly=TRUE)  # Connection to glpk as solver
library(ompr, quietly=TRUE)             # Optimization Modeling using R
library(ompr.roi, quietly=TRUE)         # Connective tissue

result <- MIPModel () %>%
  add_variable (u1, type="continuous", lb=0) %>%
  add_variable (u2, type="continuous", lb=0) %>%
  set_objective (25*u1+3500*u2, "max") %>%
  add_constraint (25*u1+3500*u2 <= 1.0) %>%
  add_constraint (14*u1+2100*u2 <= 1.0) %>%
  add_constraint (42*u1+1050*u2 <= 1.0) %>%
  add_constraint (28*u1+4200*u2 <= 1.0) %>%
  add_constraint (19*u1+2500*u2 <= 1.0) %>%
  add_constraint (14*u1+1500*u2 <= 1.0) %>%
  solve_model(with_ROI(solver = "glpk"))

u1_result <- get_solution(result, u1) 
u2_result <- get_solution(result, u2) 
alfred_score <- 25 * u1_result + 3500 * u2_result
names(alfred_score)<-""

pander(cbind(alfred_score, u1_result, u2_result), 
       caption="Alfred's Score and Results")
```

We could repeat the process for each person, simply changing the objective function.  

```{r}
result <- MIPModel () %>%
  add_variable (u1, type="continuous", lb=0) %>%
  add_variable (u2, type="continuous", lb=0) %>%
  set_objective (14*u1+2100*u2, "max") %>%
  add_constraint (25*u1+3500*u2 <= 1.0) %>%
  add_constraint (14*u1+2100*u2 <= 1.0) %>%
  add_constraint (42*u1+1050*u2 <= 1.0) %>%
  add_constraint (28*u1+4200*u2 <= 1.0) %>%
  add_constraint (19*u1+2500*u2 <= 1.0) %>%
  add_constraint (14*u1+1500*u2 <= 1.0) %>%
  solve_model(with_ROI(solver = "glpk"))

u1_result <- get_solution(result, u1) 
u2_result <- get_solution(result, u2) 
barb_score <- 14 * u1_result + 2100 * u2_result
names(barb_score)<-""

pander(cbind(barb_score, u1_result, u2_result), 
       caption="Barb's Score and Weights")
```

Let's do it for Chris.

```{r}
result <- MIPModel () %>%
  add_variable (u1, type="continuous", lb=0) %>%
  add_variable (u2, type="continuous", lb=0) %>%
  set_objective (42*u1+1050*u2, "max") %>%
  add_constraint (25*u1+3500*u2 <= 1.0) %>%
  add_constraint (14*u1+2100*u2 <= 1.0) %>%
  add_constraint (42*u1+1050*u2 <= 1.0) %>%
  add_constraint (28*u1+4200*u2 <= 1.0) %>%
  add_constraint (19*u1+2500*u2 <= 1.0) %>%
  add_constraint (14*u1+1500*u2 <= 1.0) %>%
  solve_model(with_ROI(solver = "glpk"))

u1_result <- get_solution(result, u1) 
u2_result <- get_solution(result, u2) 
chris_score <- 42 * u1_result + 1050 * u2_result
names(chris_score)<-""

pander(cbind(chris_score, u1_result, u2_result), 
       caption="Chris's Score and Weights")
```

This process of building the model for each person individually and hard coding the data into the model makes it difficult to maintain, generalize, and apply to other cases.

Let's now generalize this by building the model algebraically.  Let's define the data, $y_{r,j}$ to be the value of output _r_ for manager _j_.  Therefore, in this application, $y_{1,1}=25$ and $y_{2,1}=3500$ reflects Alfred (_j=1_) has outputs _1_ and _2_ of 25 and 3500 respectively.

We can then rewrite the formulation to the following.  The summation is over the two outputs.


$$
\begin{split}
\begin{aligned}
    \text {max } \sum_{r=1}^{2} u_r y_{r,1}\\
    \text{subject to } &  \sum_{r=1}^{2} u_r y_{r,1} \leq 1.0 \quad [Alfred]\\
     &  \sum_{r=1}^{2} u_r y_{r,2} \leq 1.0  \quad [Barb]\\
     &  \sum_{r=1}^{2} u_r y_{r,3} \leq 1.0  \quad [Chris]\\
     &  \sum_{r=1}^{2} u_r y_{r,4} \leq 1.0  \quad [Don]\\
     &  \sum_{r=1}^{2} u_r y_{r,5} \leq 1.0  \quad [Ed]\\
     &  \sum_{r=1}^{2} u_r y_{r,6} \leq 1.0  \quad [Fran]\\
     &                  u_1, u_2\geq 0  
  \end{aligned}
\end{split}
(\#eq:NLP6PeopleHArdCode)
$$

Now we will extend this further to reflect that the constraint of being less than or equal to 1.0 is the same for every manager.  A key notation to learn is the $\forall$ symbol which means to repeat for all possible values of the index.  

$$
\begin{split}
\begin{aligned}
    \text {max } \sum_{r=1}^{2} u_r y_{r,1}\\
    \text{subject to } &  \sum_{r=1}^{2} u_r y_{r,j} 
                          \leq 1.0  \; \forall \; j\\
     &                  u_r \geq 0  \; \forall \; r
  \end{aligned}
\end{split}
(\#eq:NLP6People)
$$

The $\forall$ is also used in the non-negativity constraint to indicate that for every output _r_, the weight, $u_r$, must be non-negative.  

The above formulation is nearly generalized. Let's replace the last hardcoded items remaining.  The first is that the formulation only calculates the score for first manager.  To generalize this, let's replace the _1_ in the objective function with _k_. This would allow us to calculate the optimal score for any manager, _k_. Secondly, the summations each assume that there are only two outputs. Let's replace this with$N^Y$ to serve as a count of the number of outputs.    

$$
\begin{split}
\begin{aligned}
    \text {max } \sum_{r=1}^{N^Y} u_r y_{r,k}\\
    \text{subject to } &  \sum_{r=1}^{N^Y} u_r y_{r,j} 
                          \leq 1.0 \; \forall \; j\\
     &                  u_r \geq 0  \; \forall \; r
  \end{aligned}
\end{split}
(\#eq:NLPScoringk)
$$

This formulation is now a linear programming model that will find an optimal score for manager _k_ regardless of the number of outputs and the number of other managers being considered.

## The Ratio Model

Now, let's further extend this model in incorporate inputs. Not only are the restaurant managers producing different outcomes, they are also using different resources, say capital and labor. Let's denote capital investment as $x_1$ and labor in full-time-equivalents as $x_2$.  

We can frame the question of doing a two-input, two-output study in the same way as we did for the two output example earlier. Instead of a simple score, the manager can have a ratio of weighted outputs over weighted inputs.  

For the two-input, two-output case, the formulation is given below. 

$$
\begin{split}
\begin{aligned}
    \text {max } \frac{\sum_{r=1}^{2} u_r y_{r,k}} {\sum_{i=1}^{2} v_i x_{i,k} } \\
    \text{subject to } & \frac{\sum_{r=1}^{2} u_r y_{r,k}} {\sum_{i=1}^{2} v_i x_{i,k} }
                          \leq 1 \; \forall \; j\\
                       u_r, v_i\geq 0  \; \forall \; r,i
  \end{aligned}
\end{split}
(\#eq:NLPCCRIOM-Ratio)
$$
We have two important sets of variables now.  The first is $u_r$ which is the weight on the r'th output.  The second is $v_i$ which is the weight on the _i'th_ input.  

For clarification, we make a small variation from traditional DEA notation.  Normally the number of inputs is _m_ and the number of outputs is _s_.  To make the code more readable, I will use a convention of _NX_ instead of _m_ to refer to the number of inputs (x's) and _NY_ to be the number of ouputs (y's) instead of _s_. Also, _n_ is used to denote the number of Decision Making Units (DMUs) and therefore I'll use _ND_ to indicate that in the R code.  In the mathematical formulations, superscripts are used to differentiate the the different N's resulting in $N^X$,  $N^Y$, and  $N^D$ for _NX_, _NY_, and _ND_ or _m_, _s_, and _n_ respectively. 

$$
\begin{split}
\begin{aligned}
    \text {max } \frac{\sum_{r=1}^{N^Y} u_r y_{r,k}} {\sum_{i=1}^{N^X} v_i x_{i,k} } \\
    \text{subject to } & \frac{\sum_{r=1}^{N^Y} u_r y_{r,k}} {\sum_{i=1}^{N^X} v_i x_{i,k} }
                          \leq 1 \; \forall \; j\\
                       u_r, v_i\geq 0  \; \forall \; r,i
  \end{aligned}
\end{split}
(\#eq:NLPCCRIOM-Ratio)
$$

This isn't a linear program because we are dividing functions of variables by functions of variables.  We need to make a few transformations.  First, we clear the denominator of each of the consraints resulting in the following formulation.

$$
\begin{split}
 \begin{aligned}
    \text {max } \frac{\sum_{r=1}^{N^Y} u_r y_{r,k}} {\sum_{i=1}^{N^X} v_i x_{i,k} } \\
    \text{subject to } & \sum_{r=1}^{N^Y} u_r y_{r,k} - \sum_{i=1}^{N^X} v_i x_{i,k} 
                          \leq 0 \; \forall \; j\\
                       u_r, v_i\geq 0  \; \forall \; r,i
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOM-Ratio2)
$$

Now we will convert the problem input and output constraints from inequalities into equalities by explicitly defining slack variables.  

There are an infinite number of possible combinations of numerators and denominators that can give the same ratio.  The next step is to select normalizing value for the objective function.  Let's set the denominator equal to one.  In this case, we simply add a constraint, $\sum_{i=1}^{N^X} v_i x_{i,k}$, to the linear program.  


$$
\begin{split}
 \begin{aligned}
    \text {max } \sum_{r=1}^{N^Y} u_r y_{r,k} \\
    \text{subject to } & \sum_{i=1}^{N^X} v_i x_{i,k} = 1 \\
    & \sum_{r=1}^{N^Y} u_r y_{r,k} - \sum_{i=1}^{N^X} v_i x_{i,k} 
                          \leq 0 \; \forall \; j\\
                       u_r, v_i\geq 0  \; \forall \; r,i
  \end{aligned}
   \end{split}
  (\#eq:LPCCRIOM)
$$

This linear program can then be implemented in an linear programming system.  

## Creating the LP - The Algebraic Approach

We will implement this using the ompr package again, as we did in chapters 2 and 4.  

We're going to use our data from earlier.  For this example, we will use the dataset from Kenneth Baker's third edition of _Optimization Modeling with Spreadsheets_, pages 175-178, Example 5.3 titled "Hope Valley Health Care Association." In this case, a health care organization wants to benchmark six nursing homes against each other.

```{r multiplier_model }

  XBaker1 <- matrix(c(150, 400, 320, 520, 350, 320, .2, 0.7, 1.2, 2.0, 1.2, 0.7),
                  ncol=2,dimnames=list(LETTERS[1:6],c("x1", "x2")))

  YBaker1 <- matrix(c(14000, 14000, 42000, 28000, 19000, 14000, 3500, 21000, 10500, 
                    42000, 25000, 15000),
                  ncol=2,dimnames=list(LETTERS[1:6],c("y1", "y2")))

ND <- nrow(XBaker1); NX <- ncol(XBaker1); NY <- ncol(YBaker1); # Define data size

xdata      <-XBaker1 [1:ND,]  # Call it xdata
dim(xdata) <-c(ND,NX)  # structure data correctly
ydata      <-YBaker1[1:ND,]
dim(ydata) <-c(ND,NY)
  
```

Remember the inputs are named as "x1" and"x2" to represent the _staff hours per day_ and the _supplies per day_ respectively.  The two outputs of _reimbursed patient-days_ and _privately paid patient-days_ are named "y1" and "y2".  

```{r}
YBaker1 <- matrix(c(14000, 14000, 42000, 28000, 19000, 14000, 3500, 21000, 10500, 
                    42000, 25000, 15000),
                  ncol=2,dimnames=list(LETTERS[1:6],c("y1", "y2")))

ND <- nrow(XBaker1); NX <- ncol(XBaker1); NY <- ncol(YBaker1); # Define data size

```

Note that I'm naming the data sets based on their origin and then loading them into xdata and ydata for actual operation.

```{r Structure_Results}

results.efficiency <- matrix(rep(-1.0, ND), nrow=ND, ncol=1)
results.lambda     <- matrix(rep(-1.0, ND^2), nrow=ND,ncol=ND)
results.vweight    <- matrix(rep(-1.0, ND*NX), nrow=ND,ncol=NX) 
results.uweight    <- matrix(rep(-1.0, ND*NY), nrow=ND,ncol=NY) 
results.xslack     <- matrix(rep(-1.0, ND*NX), nrow=ND,ncol=NX) 
results.yslack     <- matrix(rep(-1.0, ND*NY), nrow=ND,ncol=NY) 

DMUnames <- list(c(LETTERS[1:ND]))
Xnames<- lapply(list(rep("X",NX)),paste0,1:NX)
Ynames<- lapply(list(rep("Y",NY)),paste0,1:NY)
Vnames<- lapply(list(rep("v",NX)),paste0,1:NX)
Unames<- lapply(list(rep("u",NY)),paste0,1:NY)
SXnames<- lapply(list(rep("sx",NX)),paste0,1:NX)
SYnames<- lapply(list(rep("sy",NY)),paste0,1:NY)
Lambdanames <- lapply(list(rep("L_",ND)),paste0,LETTERS[1:ND])
  
dimnames(xdata)<-c(DMUnames,Xnames)
dimnames(ydata)<-c(DMUnames,Ynames)
dimnames(results.efficiency)<-c(DMUnames,"CCR-IO")
dimnames(results.lambda)<-c(DMUnames,Lambdanames)
dimnames(results.xslack)<-c(DMUnames,SXnames)
dimnames(results.yslack)<-c(DMUnames,SYnames)
dimnames(results.uweight)<-c(DMUnames,Unames)
dimnames(results.vweight)<-c(DMUnames,Vnames)

```

We are now ready to do the analysis.  In Baker, the analysis is done using the multiplier model.  In chapter 2 we used the envelopment model to examine this case.  Now we will use the multiplier model.

```{r Baker_example, eval=TRUE}

for (k in 1:ND) {

  result <- MIPModel() %>%
  add_variable(vweight[i], i = 1:NX, type = "continuous", lb = 0) %>%
  add_variable(uweight[r], r = 1:NY, type = "continuous", lb = 0) %>%
  set_objective(sum_expr(uweight[r] * ydata[k,r], r = 1:NY), "max") %>%
  add_constraint(sum_expr(vweight[i] * xdata[k,i], i = 1:NX) == 1) %>%
  add_constraint((sum_expr(uweight[r] * ydata[j,r], r = 1:NY)-
                    sum_expr(vweight[i] * xdata[j,i], i = 1:NX)) 
                 <= 0, j = 1:ND)
  result

  result <- solve_model(result, with_ROI(solver = "glpk", verbose = FALSE))
  results.efficiency[k] <- objective_value (result) 

  # Get the weights - Output weights
  tempvweight <- get_solution(result, vweight[i])
  results.vweight[k,] <- tempvweight[,3]

  # Get the weights- Input weights
  tempuweight <- get_solution(result, uweight[i])
  results.uweight[k,] <- tempuweight[,3]

 }

pander(cbind (results.efficiency, results.vweight, results.uweight), 
      caption="Multiplier Model Results from Baker's Example")

```

The weights from the multiplier model often have multiple alternative solutions-in other words, different values for decision variables that give the same objective function value.  In optimization, this situation is called multiple optima.  In DEA this means that the weights may be different depending upon the particular settings used for solving the linear program.  The result is that you should be careful in over interpreting the weights as well as in how you interpret results when trying to reproduce analyses.

## Future Issues

Issues to consider in the future for this chapter or other chapters.

* Weak vs. strong efficiency
* Non-Archimedean Infinitesimal
* Returns to Scale
* Adding output-oriented multiplier model
* Adding returns to scale to multiplier model

